{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ba6d2ce2-b0a1-4a50-96e3-746b58da6aab",
      "metadata": {
        "id": "ba6d2ce2-b0a1-4a50-96e3-746b58da6aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cef742-0b91-4b2c-cbe5-33735aa3c2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-df3cf428c368>:5: DtypeWarning: Columns (12,13,14,15,16,17,18,19,20,21,22,24,25,26,27,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"processed_data.csv\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# processed dataset\n",
        "df = pd.read_csv(\"processed_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load file\n",
        "import pandas as pd\n",
        "\n",
        "file_path = 'processed_data.csv'\n",
        "processed_data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the columns\n",
        "print(processed_data.columns)\n",
        "\n",
        "columns_list = list(processed_data.columns)\n",
        "print(columns_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWmHMWlYLEbI",
        "outputId": "ef98bb5f-408f-4b93-b328-af06715d89df"
      },
      "id": "cWmHMWlYLEbI",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-03f69bd48188>:5: DtypeWarning: Columns (12,13,14,15,16,17,18,19,20,21,22,24,25,26,27,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  processed_data = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['FL_DATE', 'CRS_DEP_TIME', 'OP_UNIQUE_CARRIER', 'DEST',\n",
            "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt',\n",
            "       'visibility_statute_mi', 'temperature_c', 'dewpoint_c', 'altimeter_hpa',\n",
            "       'Flight_Status', 'Carrier_AA', 'Carrier_AS', 'Carrier_B6', 'Carrier_DL',\n",
            "       'Carrier_F9', 'Carrier_G4', 'Carrier_HA', 'Carrier_NK', 'Carrier_OO',\n",
            "       'Carrier_UA', 'Carrier_WN', 'DEST_REGION', 'Dest_Region_Midwest',\n",
            "       'Dest_Region_Mountain', 'Dest_Region_Northeast', 'Dest_Region_OCONUS',\n",
            "       'Dest_Region_South', 'Dest_Region_Southwest', 'Dest_Region_West',\n",
            "       'Flight_Status_Binary'],\n",
            "      dtype='object')\n",
            "['FL_DATE', 'CRS_DEP_TIME', 'OP_UNIQUE_CARRIER', 'DEST', 'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'visibility_statute_mi', 'temperature_c', 'dewpoint_c', 'altimeter_hpa', 'Flight_Status', 'Carrier_AA', 'Carrier_AS', 'Carrier_B6', 'Carrier_DL', 'Carrier_F9', 'Carrier_G4', 'Carrier_HA', 'Carrier_NK', 'Carrier_OO', 'Carrier_UA', 'Carrier_WN', 'DEST_REGION', 'Dest_Region_Midwest', 'Dest_Region_Mountain', 'Dest_Region_Northeast', 'Dest_Region_OCONUS', 'Dest_Region_South', 'Dest_Region_Southwest', 'Dest_Region_West', 'Flight_Status_Binary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f019d9e1-7312-4923-bc3d-4352acc7c43a",
      "metadata": {
        "id": "f019d9e1-7312-4923-bc3d-4352acc7c43a"
      },
      "source": [
        "### Training, Validation, Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1713004-a8b2-4fbe-b1ae-4d53cfa082a9",
      "metadata": {
        "id": "e1713004-a8b2-4fbe-b1ae-4d53cfa082a9"
      },
      "source": [
        "# **Split Data 70/15/15**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Balancing the Dataset (Undersampling)"
      ],
      "metadata": {
        "id": "0N-qe3R9QX3H"
      },
      "id": "0N-qe3R9QX3H"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "#  features and target\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# Separate the majority and minority classes\n",
        "majority_class = train_data[train_data[target] == 0]\n",
        "minority_class = train_data[train_data[target] == 1]\n",
        "\n",
        "# Undersample the majority class\n",
        "majority_class_downsampled = resample(majority_class,\n",
        "                                      replace=False,\n",
        "                                      n_samples=len(minority_class),\n",
        "                                      random_state=42)\n",
        "\n",
        "# Combine the downsampled majority class with the minority class\n",
        "balanced_train_data = pd.concat([majority_class_downsampled, minority_class])\n",
        "\n",
        "# Separate back into X and y\n",
        "X_train_balanced = balanced_train_data.drop(columns=[target])\n",
        "y_train_balanced = balanced_train_data[target]\n",
        "\n",
        "# Check\n",
        "print(f\"Class distribution in training set after balancing:\\n{y_train_balanced.value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X5-7ZE3QVFD",
        "outputId": "7120c3b5-3af5-4b8f-e70e-206856399ee8"
      },
      "id": "-X5-7ZE3QVFD",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in training set after balancing:\n",
            "Flight_Status_Binary\n",
            "0.0    13592\n",
            "1.0    13592\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "features_to_use = [\n",
        "    'wind_dir_degrees', 'wind_speed_kt', 'temperature_c', 'dewpoint_c',\n",
        "    'visibility_statute_mi', 'altimeter_hpa', 'Carrier_AA', 'Carrier_AS',\n",
        "    'Carrier_B6', 'Carrier_DL', 'Carrier_F9', 'Carrier_G4', 'Carrier_HA',\n",
        "    'Carrier_NK', 'Carrier_OO', 'Carrier_UA', 'Carrier_WN', 'Dest_Region_Midwest',\n",
        "    'Dest_Region_Mountain', 'Dest_Region_Northeast', 'Dest_Region_OCONUS',\n",
        "    'Dest_Region_South', 'Dest_Region_Southwest', 'Dest_Region_West'\n",
        "]\n",
        "\n",
        "# target variable\n",
        "target = 'Flight_Status_Binary'"
      ],
      "metadata": {
        "id": "YU6CRxxEP0i4"
      },
      "id": "YU6CRxxEP0i4",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with NaN in the target column\n",
        "processed_data = processed_data.dropna(subset=[target])\n",
        "\n",
        "# Now split again\n",
        "X = processed_data[features_to_use]\n",
        "y = processed_data[target]\n",
        "\n",
        "# Split into training and temp (validation + test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Split temp into validation and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")"
      ],
      "metadata": {
        "id": "0bP_HNcB2eIi"
      },
      "id": "0bP_HNcB2eIi",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = processed_data[features_to_use]\n",
        "y = processed_data[target]\n",
        "\n",
        "# Split into training and temp (validation + test) datasets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Split temp into validation and test sets (50% for validation, 50% for test)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Check the sizes of the splits\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWvxXComQSSu",
        "outputId": "9acfaf0c-45ed-4acb-925c-aac51d742615"
      },
      "id": "QWvxXComQSSu",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 106749\n",
            "Validation set size: 22875\n",
            "Test set size: 22875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Scaling"
      ],
      "metadata": {
        "id": "Vg60F8fyQeN0"
      },
      "id": "Vg60F8fyQeN0"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# transform the training data\n",
        "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
        "\n",
        "# Transform the validation and test data\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Check\n",
        "print(f\"Scaled Training data shape: {X_train_scaled.shape}\")\n",
        "print(f\"Scaled Validation data shape: {X_val_scaled.shape}\")\n",
        "print(f\"Scaled Test data shape: {X_test_scaled.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N60uwBnpQWwD",
        "outputId": "c60b1b79-4da0-436b-d3de-2ccbfbe3244f"
      },
      "id": "N60uwBnpQWwD",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Training data shape: (27184, 24)\n",
            "Scaled Validation data shape: (22875, 24)\n",
            "Scaled Test data shape: (22875, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training (RandomForest) for 70/15/15 split"
      ],
      "metadata": {
        "id": "_YFvk8E6MSfT"
      },
      "id": "_YFvk8E6MSfT"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# RandomForest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model using the scaled training data\n",
        "rf_model.fit(X_train_scaled, y_train_balanced)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_preds = rf_model.predict(X_val_scaled)\n",
        "\n",
        "# Evaluate performance on the validation set\n",
        "print(\"Validation Set Performance:\")\n",
        "print(confusion_matrix(y_val, val_preds))\n",
        "print(classification_report(y_val, val_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0UAo-BzQcvy",
        "outputId": "698dab1f-487b-4cf4-baf7-327d4d7c6c71"
      },
      "id": "l0UAo-BzQcvy",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Performance:\n",
            "[[12764  7198]\n",
            " [ 1092  1821]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.64      0.75     19962\n",
            "         1.0       0.20      0.63      0.31      2913\n",
            "\n",
            "    accuracy                           0.64     22875\n",
            "   macro avg       0.56      0.63      0.53     22875\n",
            "weighted avg       0.83      0.64      0.70     22875\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "test_preds = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate performance on the test set\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(classification_report(y_test, test_preds))"
      ],
      "metadata": {
        "id": "hOtexZJPQgDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4a7f06-9998-427d-f967-263718b69c14"
      },
      "id": "hOtexZJPQgDX",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set Performance:\n",
            "[[12703  7260]\n",
            " [ 1049  1863]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.64      0.75     19963\n",
            "         1.0       0.20      0.64      0.31      2912\n",
            "\n",
            "    accuracy                           0.64     22875\n",
            "   macro avg       0.56      0.64      0.53     22875\n",
            "weighted avg       0.83      0.64      0.70     22875\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results for 70/15/15 Split\n",
        "Validation Set:\n",
        "\n",
        "The model was good at predicting on-time flights (94% precision), but it had trouble predicting delayed/canceled flights (only 18% precision).\n",
        "\n",
        "It correctly identified 64% of all the delayed/canceled flights, but missed a lot of them.\n",
        "\n",
        "Test Set:\n",
        "\n",
        "The results were similar to the validation set: the model was good at predicting on-time flights (94% precision), but struggled with delayed/canceled flights (18% precision).\n",
        "\n",
        "It correctly identified 64% of delayed/canceled flights, but still missed many."
      ],
      "metadata": {
        "id": "ULUQoGajO7Z0"
      },
      "id": "ULUQoGajO7Z0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **80/10/10 split**"
      ],
      "metadata": {
        "id": "V2xciIfS38_b"
      },
      "id": "V2xciIfS38_b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Since our goal number 2 is to reduce delay times by informing logistics, its better to catch more delays. Using a lower threshold to increase recall, since missing a delay would be worse than predicting one that doesn't end up happening"
      ],
      "metadata": {
        "id": "xc0fTnDIDyn-"
      },
      "id": "xc0fTnDIDyn-"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into 80% training, 10% validation, and 10% testing\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Split the remaining data (X_temp, y_temp) into 50% validation and 50% test (i.e., 10% each)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Check the split sizes\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Test set size:\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTDaY-SA3o_a",
        "outputId": "1054b8db-af8d-4c31-bff8-09fac354ee25"
      },
      "id": "gTDaY-SA3o_a",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 121999\n",
            "Validation set size: 15250\n",
            "Test set size: 15250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Drop rows where the target is missing\n",
        "df_cleaned = df.dropna(subset=['Flight_Status_Binary'])\n",
        "\n",
        "# Step 2: First split (80% train, 20% temp)\n",
        "train_df_80, temp_df = train_test_split(\n",
        "    df_cleaned, test_size=0.20, random_state=42, stratify=df_cleaned['Flight_Status_Binary']\n",
        ")\n",
        "\n",
        "# Step 3: Split the 20% temp into 10% val, 10% test\n",
        "val_df_10, test_df_10 = train_test_split(\n",
        "    temp_df, test_size=0.50, random_state=42, stratify=temp_df['Flight_Status_Binary']\n",
        ")\n",
        "\n",
        "# Confirm sizes\n",
        "print(\"Train size:\", len(train_df_80))\n",
        "print(\"Validation size:\", len(val_df_10))\n",
        "print(\"Test size:\", len(test_df_10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dafH6DTF4MfD",
        "outputId": "96f43eca-0a21-4c68-9c23-4bb9a92149be"
      },
      "id": "dafH6DTF4MfD",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 93888\n",
            "Validation size: 11736\n",
            "Test size: 11736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for 80/10/10 split\n"
      ],
      "metadata": {
        "id": "nC9dcx8g3R4K"
      },
      "id": "nC9dcx8g3R4K"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Features used for modeling\n",
        "features = [\n",
        "    'wind_dir_degrees', 'wind_speed_kt', 'temperature_c', 'dewpoint_c',\n",
        "    'visibility_statute_mi', 'altimeter_hpa',\n",
        "    'Carrier_AA', 'Carrier_AS', 'Carrier_B6', 'Carrier_DL', 'Carrier_F9',\n",
        "    'Carrier_G4', 'Carrier_HA', 'Carrier_NK', 'Carrier_OO', 'Carrier_UA', 'Carrier_WN',\n",
        "    'Dest_Region_Midwest', 'Dest_Region_Mountain', 'Dest_Region_Northeast',\n",
        "    'Dest_Region_OCONUS', 'Dest_Region_South', 'Dest_Region_Southwest', 'Dest_Region_West'\n",
        "]\n",
        "\n",
        "# Split X and y\n",
        "X_train = train_df_80[features]\n",
        "y_train = train_df_80['Flight_Status_Binary']\n",
        "\n",
        "X_val = val_df_10[features]\n",
        "y_val = val_df_10['Flight_Status_Binary']\n",
        "\n",
        "X_test = test_df_10[features]\n",
        "y_test = test_df_10['Flight_Status_Binary']\n",
        "\n",
        "# 🔁 Undersample the majority class in training data\n",
        "majority = train_df_80[train_df_80['Flight_Status_Binary'] == 0]\n",
        "minority = train_df_80[train_df_80['Flight_Status_Binary'] == 1]\n",
        "\n",
        "majority_downsampled = resample(\n",
        "    majority, replace=False, n_samples=len(minority), random_state=42\n",
        ")\n",
        "\n",
        "balanced_train_df = pd.concat([majority_downsampled, minority]).sample(frac=1, random_state=42)\n",
        "\n",
        "X_train_bal = balanced_train_df[features]\n",
        "y_train_bal = balanced_train_df['Flight_Status_Binary']\n",
        "\n",
        "# 📏 Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_bal)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 🚀 Train logistic regression\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logreg.fit(X_train_scaled, y_train_bal)\n",
        "\n",
        "# 🔍 Evaluate on validation set\n",
        "val_preds = logreg.predict(X_val_scaled)\n",
        "print(\"🟦 Validation Set Performance:\")\n",
        "print(confusion_matrix(y_val, val_preds))\n",
        "print(classification_report(y_val, val_preds))\n",
        "\n",
        "# 🔍 Evaluate on test set\n",
        "test_preds = logreg.predict(X_test_scaled)\n",
        "print(\"🟩 Test Set Performance:\")\n",
        "print(confusion_matrix(y_test, test_preds))\n",
        "print(classification_report(y_test, test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg0jRaU63UWO",
        "outputId": "f04e3d9d-f27a-4c72-8bb8-ef9a43156efe"
      },
      "id": "Pg0jRaU63UWO",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟦 Validation Set Performance:\n",
            "[[5607 4224]\n",
            " [ 750 1155]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.57      0.69      9831\n",
            "         1.0       0.21      0.61      0.32      1905\n",
            "\n",
            "    accuracy                           0.58     11736\n",
            "   macro avg       0.55      0.59      0.50     11736\n",
            "weighted avg       0.77      0.58      0.63     11736\n",
            "\n",
            "🟩 Test Set Performance:\n",
            "[[5593 4238]\n",
            " [ 762 1143]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.57      0.69      9831\n",
            "         1.0       0.21      0.60      0.31      1905\n",
            "\n",
            "    accuracy                           0.57     11736\n",
            "   macro avg       0.55      0.58      0.50     11736\n",
            "weighted avg       0.77      0.57      0.63     11736\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion for Logistic 80/10/10 model"
      ],
      "metadata": {
        "id": "jvdp3ustH8Sf"
      },
      "id": "jvdp3ustH8Sf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic regression model achieved a recall of 0.60 on the test set, meaning it correctly identified 60% of delayed or canceled flights. However, its precision was lower at 0.21, meaning many on-time flights were incorrectly flagged. With an F1 score of 0.31, it shows a balanced but modest performance. This model is helpful for catching delays early, but it comes with more false alarms—something to consider when prioritizing precision vs. recall.\n"
      ],
      "metadata": {
        "id": "foPUGMFKIB0-"
      },
      "id": "foPUGMFKIB0-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost with 80/10/10 Split"
      ],
      "metadata": {
        "id": "uuP256XpCXIK"
      },
      "id": "uuP256XpCXIK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all features are numeric\n",
        "for df in [train_df_80, val_df_10, test_df_10]:\n",
        "    df[features] = df[features].apply(pd.to_numeric, errors='coerce')"
      ],
      "metadata": {
        "id": "hhkWEJ2_ExD3"
      },
      "id": "hhkWEJ2_ExD3",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Define features and target\n",
        "features = [\n",
        "    'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'visibility_statute_mi',\n",
        "    'temperature_c', 'dewpoint_c', 'altimeter_hpa',\n",
        "    'Carrier_AA', 'Carrier_AS', 'Carrier_B6', 'Carrier_DL', 'Carrier_F9', 'Carrier_G4',\n",
        "    'Carrier_HA', 'Carrier_NK', 'Carrier_OO', 'Carrier_UA', 'Carrier_WN',\n",
        "    'Dest_Region_Midwest', 'Dest_Region_Mountain', 'Dest_Region_Northeast',\n",
        "    'Dest_Region_OCONUS', 'Dest_Region_South', 'Dest_Region_Southwest', 'Dest_Region_West'\n",
        "]\n",
        "\n",
        "target = 'Flight_Status_Binary'"
      ],
      "metadata": {
        "id": "vCF25QamDuOF"
      },
      "id": "vCF25QamDuOF",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 2: Train the XGBoost model on the training set\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X_train_80.astype(float), y_train_80)\n",
        "\n",
        "# Step 3: Predict probabilities for validation and test sets\n",
        "val_probs = xgb_model.predict_proba(X_val_10.astype(float))[:, 1]\n",
        "test_probs = xgb_model.predict_proba(X_test_10.astype(float))[:, 1]\n",
        "\n",
        "# Step 4: Apply custom threshold at 20\n",
        "custom_threshold = 0.20\n",
        "val_preds_custom = (val_probs >= custom_threshold).astype(int)\n",
        "test_preds_custom = (test_probs >= custom_threshold).astype(int)\n",
        "\n",
        "# Step 4: Evaluate performance\n",
        "print(f\"\\n Validation Confusion Matrix (Threshold = {custom_threshold}):\")\n",
        "print(confusion_matrix(y_val_10, val_preds_custom))\n",
        "print(f\"Precision: {precision_score(y_val_10, val_preds_custom):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_val_10, val_preds_custom):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_val_10, val_preds_custom):.2f}\")\n",
        "\n",
        "print(f\"\\n Test Confusion Matrix (Threshold = {custom_threshold}):\")\n",
        "print(confusion_matrix(y_test_10, test_preds_custom))\n",
        "print(f\"Precision: {precision_score(y_test_10, test_preds_custom):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test_10, test_preds_custom):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test_10, test_preds_custom):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVwyJcwqEiwI",
        "outputId": "5597a807-cee1-41e7-a1c9-c0c3218dc9e9"
      },
      "id": "AVwyJcwqEiwI",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:34:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Confusion Matrix (Threshold = 0.2):\n",
            "[[7678 2153]\n",
            " [ 901 1004]]\n",
            "Precision: 0.32\n",
            "Recall: 0.53\n",
            "F1 Score: 0.40\n",
            "\n",
            " Test Confusion Matrix (Threshold = 0.2):\n",
            "[[7712 2119]\n",
            " [ 934  971]]\n",
            "Precision: 0.31\n",
            "Recall: 0.51\n",
            "F1 Score: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion for XGBoost with .20 threshold (80/10/10 split)\n",
        "Our XGBoost model with the 80/10/10 split and 0.2 threshold is helping us meet our project goals. It catches over half of the delayed or canceled flights (recall = 0.51) and gives a balanced performance (F1 score = 0.39). This means we can better predict delays and help teams act early to reduce them."
      ],
      "metadata": {
        "id": "pK2rHxIgG9US"
      },
      "id": "pK2rHxIgG9US"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest 80/10/10 Split"
      ],
      "metadata": {
        "id": "rPidQy10HaX0"
      },
      "id": "rPidQy10HaX0"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_model_80 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model_80.fit(X_train_80, y_train_80)\n",
        "\n",
        "# Predict probabilities\n",
        "val_probs_rf = rf_model_80.predict_proba(X_val_10)[:, 1]\n",
        "test_probs_rf = rf_model_80.predict_proba(X_test_10)[:, 1]\n",
        "\n",
        "# Apply custom threshold\n",
        "rf_threshold = 0.2\n",
        "val_preds_rf_custom = (val_probs_rf >= rf_threshold).astype(int)\n",
        "test_preds_rf_custom = (test_probs_rf >= rf_threshold).astype(int)\n",
        "\n",
        "# Evaluate on validation set\n",
        "print(\"✅ Validation Confusion Matrix (Threshold = 0.2):\")\n",
        "print(confusion_matrix(y_val_10, val_preds_rf_custom))\n",
        "print(\"Precision:\", round(precision_score(y_val_10, val_preds_rf_custom), 2))\n",
        "print(\"Recall:\", round(recall_score(y_val_10, val_preds_rf_custom), 2))\n",
        "print(\"F1 Score:\", round(f1_score(y_val_10, val_preds_rf_custom), 2))\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\n✅ Test Confusion Matrix (Threshold = 0.2):\")\n",
        "print(confusion_matrix(y_test_10, test_preds_rf_custom))\n",
        "print(\"Precision:\", round(precision_score(y_test_10, test_preds_rf_custom), 2))\n",
        "print(\"Recall:\", round(recall_score(y_test_10, test_preds_rf_custom), 2))\n",
        "print(\"F1 Score:\", round(f1_score(y_test_10, test_preds_rf_custom), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJOBoWTpGYPL",
        "outputId": "d9752079-514f-4378-8edd-38d1450c18c9"
      },
      "id": "MJOBoWTpGYPL",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Validation Confusion Matrix (Threshold = 0.2):\n",
            "[[7434 2397]\n",
            " [ 871 1034]]\n",
            "Precision: 0.3\n",
            "Recall: 0.54\n",
            "F1 Score: 0.39\n",
            "\n",
            "✅ Test Confusion Matrix (Threshold = 0.2):\n",
            "[[7486 2345]\n",
            " [ 950  955]]\n",
            "Precision: 0.29\n",
            "Recall: 0.5\n",
            "F1 Score: 0.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion for Random forest\n",
        "\n",
        "With a threshold of 0.2, the Random Forest model achieved a precision of 0.30, recall of 0.54, and F1 score of 0.39 on the validation set. On the test set, it had a precision of 0.29, recall of 0.50, and F1 score of 0.37. This means the model is doing a better job identifying delayed flights (good recall), though the trade-off is more false positives. It’s a solid step toward meeting our goal of early delay detection for better operational planning"
      ],
      "metadata": {
        "id": "1uihK1wZIFTS"
      },
      "id": "1uihK1wZIFTS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summary of Models"
      ],
      "metadata": {
        "id": "BE74IEXuIzP7"
      },
      "id": "BE74IEXuIzP7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use XGBoost if we want the best balance between catching delays (recall) and avoiding false alarms (precision).\n",
        "\n",
        "Logistic regression is good for catching more delays (highest recall), but it flags more on-time flights incorrectly.\n",
        "\n",
        "Random Forest is strong, but slightly behind XGBoost in precision and F1 score.\n",
        "\n",
        "### Best Results?\n",
        "XGBoost had the best F1 score and highest precision, which means its balanced and identifies delays while ALSO minimizing false positives."
      ],
      "metadata": {
        "id": "3BmOie9nI25Y"
      },
      "id": "3BmOie9nI25Y"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# model results\n",
        "model_comparison = pd.DataFrame({\n",
        "    'Model': ['Random Forest', 'Logistic Regression', 'XGBoost'],\n",
        "    'Precision': [0.29, 0.21, 0.31],\n",
        "    'Recall': [0.50, 0.60, 0.51],\n",
        "    'F1 Score': [0.37, 0.31, 0.39]\n",
        "})\n",
        "\n",
        "# table\n",
        "model_comparison.sort_values(by='F1 Score', ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "dX03x3E5Hfup",
        "outputId": "89f1e73b-d9b2-4e0e-b699-6ccfeb363373"
      },
      "id": "dX03x3E5Hfup",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model  Precision  Recall  F1 Score\n",
              "0              XGBoost       0.31    0.51      0.39\n",
              "1        Random Forest       0.29    0.50      0.37\n",
              "2  Logistic Regression       0.21    0.60      0.31"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1d1ba81-144e-44bc-b23a-f79b3747a110\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1d1ba81-144e-44bc-b23a-f79b3747a110')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1d1ba81-144e-44bc-b23a-f79b3747a110 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1d1ba81-144e-44bc-b23a-f79b3747a110');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b03fcd46-903b-4447-a438-992f24880bea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b03fcd46-903b-4447-a438-992f24880bea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b03fcd46-903b-4447-a438-992f24880bea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"model_comparison\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"XGBoost\",\n          \"Random Forest\",\n          \"Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05291502622129181,\n        \"min\": 0.21,\n        \"max\": 0.31,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.31,\n          0.29,\n          0.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.055075705472861,\n        \"min\": 0.5,\n        \"max\": 0.6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.51,\n          0.5,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04163331998932266,\n        \"min\": 0.31,\n        \"max\": 0.39,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.39,\n          0.37,\n          0.31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}