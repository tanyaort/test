{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "3082c1b5-4ec4-4d6d-8aa9-27171a97ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "execution_state": "idle",
   "id": "1d668bf9-7073-4f2a-a6ca-4defd36c1ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FL_DATE CRS_DEP_TIME  DEP_TIME OP_UNIQUE_CARRIER  OP_CARRIER_FL_NUM  \\\n",
      "0  2023-01-01     06:10:00  06:05:00                DL                977   \n",
      "1  2023-01-01     06:15:00  06:17:00                DL               2423   \n",
      "2  2023-01-01     06:15:00  06:44:00                AA               1651   \n",
      "3  2023-01-01     06:15:00  06:15:00                DL                820   \n",
      "4  2023-01-01     06:15:00  06:13:00                DL                914   \n",
      "\n",
      "  DEST  DEP_DEL15  CANCELLED CANCELLATION_CODE  CARRIER_DELAY  ...  NAS_DELAY  \\\n",
      "0  DTW          0          0               NaN              0  ...          0   \n",
      "1  SLC          0          0               NaN              0  ...          0   \n",
      "2  CLT          1          0               NaN              0  ...          0   \n",
      "3  ATL          0          0               NaN              0  ...          0   \n",
      "4  MSP          0          0               NaN              0  ...          0   \n",
      "\n",
      "   SECURITY_DELAY  LATE_AIRCRAFT_DELAY  wind_dir_degrees  wind_speed_kt  \\\n",
      "0               0                    0             290.0            7.0   \n",
      "1               0                    0             290.0            7.0   \n",
      "2               0                    0             290.0            7.0   \n",
      "3               0                    0             290.0            7.0   \n",
      "4               0                    0             290.0            7.0   \n",
      "\n",
      "   wind_gust_kt  visibility_statute_mi  temperature_c  dewpoint_c  \\\n",
      "0          19.0                    6.0           13.3        10.0   \n",
      "1          19.0                    6.0           13.3        10.0   \n",
      "2          19.0                    6.0           13.3        10.0   \n",
      "3          19.0                    6.0           13.3        10.0   \n",
      "4          19.0                    6.0           13.3        10.0   \n",
      "\n",
      "   altimeter_hpa  \n",
      "0          29.82  \n",
      "1          29.82  \n",
      "2          29.82  \n",
      "3          29.82  \n",
      "4          29.82  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Index(['FL_DATE', 'CRS_DEP_TIME', 'DEP_TIME', 'OP_UNIQUE_CARRIER',\n",
      "       'OP_CARRIER_FL_NUM', 'DEST', 'DEP_DEL15', 'CANCELLED',\n",
      "       'CANCELLATION_CODE', 'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY',\n",
      "       'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY', 'wind_dir_degrees',\n",
      "       'wind_speed_kt', 'wind_gust_kt', 'visibility_statute_mi',\n",
      "       'temperature_c', 'dewpoint_c', 'altimeter_hpa'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# merged dataset\n",
    "raw_df = pd.read_csv(\"2_raw_data/raw_merged/raw_merged_data.csv\")\n",
    "\n",
    "# Preview\n",
    "print(raw_df.head())\n",
    "print(raw_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "execution_state": "idle",
   "id": "dc94253d-5afe-4fc4-b883-e573f4adb8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    89.337823\n",
      "1    10.662177\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a new binary target: 1 if delayed or cancelled, else 0\n",
    "raw_df[\"TARGET\"] = np.where((raw_df[\"DEP_DEL15\"] == 1) | (raw_df[\"CANCELLED\"] == 1), 1, 0)\n",
    "\n",
    "# Check balance\n",
    "print(raw_df[\"TARGET\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b84215-a757-45e2-b44b-822df4bf2b81",
   "metadata": {},
   "source": [
    "## Undersample the Majority Class (Data Balancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "a9c7ed04-e78f-4f2f-93f9-985530fd2006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "majority_df = raw_df[raw_df[\"TARGET\"] == 0]\n",
    "minority_df = raw_df[raw_df[\"TARGET\"] == 1]\n",
    "\n",
    "# Undersample the majority class\n",
    "majority_downsampled = majority_df.sample(n=len(minority_df), random_state=42)\n",
    "\n",
    "# Combine balanced dataset\n",
    "balanced_df = pd.concat([majority_downsampled, minority_df])\n",
    "\n",
    "# Shuffle the rows\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new balance\n",
    "print(balanced_df[\"TARGET\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1583d-a5ad-4c08-8945-089d2056e740",
   "metadata": {},
   "source": [
    "## Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_state": "idle",
   "id": "1b4183c0-b788-4cdf-b69b-22473015fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 27704\n",
      "Validation set size: 5937\n",
      "Test set size: 5937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split: 70% Train, 15% Validation, 15% Test\n",
    "train_df, temp_df = train_test_split(\n",
    "    balanced_df,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=balanced_df[\"TARGET\"]\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=temp_df[\"TARGET\"]\n",
    ")\n",
    "\n",
    "# Confirm split sizes\n",
    "print(\"Train set size:\", len(train_df))\n",
    "print(\"Validation set size:\", len(val_df))\n",
    "print(\"Test set size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_state": "idle",
   "id": "4f8d9d80-f215-4bd2-96c1-365d59c60bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (27704, 92)\n",
      "Validation set shape: (5937, 92)\n",
      "Test set shape: (5937, 92)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select final features\n",
    "features_to_use = [\n",
    "    'DEP_TIME', 'DEP_DEL15', 'CANCELLED',               # Flight performance features\n",
    "    'wind_dir_degrees', 'wind_speed_kt', 'temperature_c', \n",
    "    'dewpoint_c', 'visibility_statute_mi', 'altimeter_hpa',  # Weather features\n",
    "    'OP_UNIQUE_CARRIER', 'DEST'                         \n",
    "]\n",
    "\n",
    "# 2: (X) and target (y)\n",
    "X = train_df[features_to_use]\n",
    "y = train_df['TARGET']\n",
    "\n",
    "# 3: One-Hot Encode categorical variables\n",
    "# This creates binary columns for each unique value\n",
    "X = pd.get_dummies(X, columns=['OP_UNIQUE_CARRIER', 'DEST'])\n",
    "\n",
    "# 4: Lets Do the same for validation and test sets\n",
    "X_val = pd.get_dummies(val_df[features_to_use], columns=['OP_UNIQUE_CARRIER', 'DEST'])\n",
    "X_test = pd.get_dummies(test_df[features_to_use], columns=['OP_UNIQUE_CARRIER', 'DEST'])\n",
    "\n",
    "# 5: Align validation/test sets to match training columns\n",
    "X_val = X_val.reindex(columns=X.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# 6: val/test\n",
    "y_val = val_df['TARGET']\n",
    "y_test = test_df['TARGET']\n",
    "\n",
    "# Confirm final shapes of datasets\n",
    "print(\"Training set shape:\", X.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5682d91-8cd7-454a-806b-94a00dc3228d",
   "metadata": {},
   "source": [
    "## Feature Scaling before training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "execution_state": "idle",
   "id": "39bce200-1200-4e84-b368-ac351998c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first select features to use, we are using weather and flight-related features for this model training\n",
    "features_to_use = [\n",
    "    'wind_dir_degrees', 'wind_speed_kt',\n",
    "    'temperature_c', 'dewpoint_c', 'visibility_statute_mi', 'altimeter_hpa',\n",
    "    'OP_UNIQUE_CARRIER', 'DEST'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "execution_state": "idle",
   "id": "abf207fc-1018-4544-9f70-da98a5565ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then split features from each dataset\n",
    "# selected features from training, validation and test sets\n",
    "X = train_df[features_to_use].copy()\n",
    "X_val = val_df[features_to_use].copy()\n",
    "X_test = test_df[features_to_use].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "execution_state": "idle",
   "id": "f580aa25-b5ee-464c-bc52-40b3e588265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the categorical features \n",
    "# lets convert the OP_UNIQUE_CARRIER abd DEST to binary dummy variables\n",
    "X = pd.get_dummies(X, columns=['OP_UNIQUE_CARRIER', 'DEST'])\n",
    "X_val = pd.get_dummies(X_val, columns=['OP_UNIQUE_CARRIER', 'DEST'])\n",
    "X_test = pd.get_dummies(X_test, columns=['OP_UNIQUE_CARRIER', 'DEST'])\n",
    "\n",
    "# Align with training set columns\n",
    "X_val = X_val.reindex(columns=X.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "execution_state": "idle",
   "id": "2949ac76-c6da-4682-853b-a4ebe636c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize values and scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfb1c4-b659-454c-a077-80e3afd2d662",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "execution_state": "idle",
   "id": "0ef2ecab-1a12-4947-a6a4-259f37f28551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation Set Performance:\n",
      "[[1890 1078]\n",
      " [1031 1938]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      2968\n",
      "           1       0.64      0.65      0.65      2969\n",
      "\n",
      "    accuracy                           0.64      5937\n",
      "   macro avg       0.64      0.64      0.64      5937\n",
      "weighted avg       0.64      0.64      0.64      5937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# train the model on the training data\n",
    "rf_model.fit(X_scaled, y)\n",
    "\n",
    "# make predictions on the validation set\n",
    "val_preds = rf_model.predict(X_val_scaled)\n",
    "\n",
    "# check performance\n",
    "print(\"✅ Validation Set Performance:\")\n",
    "print(confusion_matrix(y_val, val_preds))\n",
    "print(classification_report(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978095f-189c-43af-938a-97719f648454",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We trained a Random Forest model to predict flight delays and cancellations, and it achieved around 64% accuracy on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de2c0d-c82e-4489-b954-9dff39ce5b6e",
   "metadata": {},
   "source": [
    "The model predicted both delayed/cancelled flights (1) and on-time flights (0) fairly evenly, with F1 scores of 0.64–0.65 for each class. This means the model is equally balanced in identifying delays and non-delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96441cd-452e-461d-be0f-b81433c95525",
   "metadata": {},
   "source": [
    "## Reduction in Operational Costs Due to Delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4a071-424d-486b-bf6e-0a1346d22db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10907b23-71f3-48d0-ae55-0354403c73f7",
   "metadata": {},
   "source": [
    "## Correlation Between Weather and Delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd9620-256f-44aa-bca0-1cfdbab5d93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
